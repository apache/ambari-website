"use strict";(self.webpackChunkambari_website=self.webpackChunkambari_website||[]).push([[8303],{3905:(e,a,t)=>{t.d(a,{Zo:()=>l,kt:()=>h});var r=t(7294);function n(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function s(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);a&&(r=r.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,r)}return t}function i(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?s(Object(t),!0).forEach((function(a){n(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):s(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function o(e,a){if(null==e)return{};var t,r,n=function(e,a){if(null==e)return{};var t,r,n={},s=Object.keys(e);for(r=0;r<s.length;r++)t=s[r],a.indexOf(t)>=0||(n[t]=e[t]);return n}(e,a);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(r=0;r<s.length;r++)t=s[r],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(n[t]=e[t])}return n}var c=r.createContext({}),p=function(e){var a=r.useContext(c),t=a;return e&&(t="function"==typeof e?e(a):i(i({},a),e)),t},l=function(e){var a=p(e.components);return r.createElement(c.Provider,{value:a},e.children)},m={inlineCode:"code",wrapper:function(e){var a=e.children;return r.createElement(r.Fragment,{},a)}},d=r.forwardRef((function(e,a){var t=e.components,n=e.mdxType,s=e.originalType,c=e.parentName,l=o(e,["components","mdxType","originalType","parentName"]),d=p(t),h=n,u=d["".concat(c,".").concat(h)]||d[h]||m[h]||s;return t?r.createElement(u,i(i({ref:a},l),{},{components:t})):r.createElement(u,i({ref:a},l))}));function h(e,a){var t=arguments,n=a&&a.mdxType;if("string"==typeof e||n){var s=t.length,i=new Array(s);i[0]=d;var o={};for(var c in a)hasOwnProperty.call(a,c)&&(o[c]=a[c]);o.originalType=e,o.mdxType="string"==typeof e?e:n,i[1]=o;for(var p=2;p<s;p++)i[p]=t[p];return r.createElement.apply(null,i)}return r.createElement.apply(null,t)}d.displayName="MDXCreateElement"},3411:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>c,contentTitle:()=>i,default:()=>m,frontMatter:()=>s,metadata:()=>o,toc:()=>p});var r=t(7462),n=(t(7294),t(3905));const s={},i="How-To Define Stacks and Services",o={unversionedId:"ambari-design/stack-and-services/how-to-define-stacks-and-services",id:"ambari-design/stack-and-services/how-to-define-stacks-and-services",title:"How-To Define Stacks and Services",description:"Services managed by Ambari are defined in its stacks folder .",source:"@site/docs/ambari-design/stack-and-services/how-to-define-stacks-and-services.md",sourceDirName:"ambari-design/stack-and-services",slug:"/ambari-design/stack-and-services/how-to-define-stacks-and-services",permalink:"/docs/next/ambari-design/stack-and-services/how-to-define-stacks-and-services",draft:!1,editUrl:"https://github.com/vivostar/vivostar.github.io/tree/master/docs/ambari-design/stack-and-services/how-to-define-stacks-and-services.md",tags:[],version:"current",frontMatter:{},sidebar:"ambariSidebar",previous:{title:"Extensions",permalink:"/docs/next/ambari-design/stack-and-services/extensions"},next:{title:"Management Packs",permalink:"/docs/next/ambari-design/stack-and-services/management-packs"}},c={},p=[{value:"Define Service",id:"define-service",level:2},{value:"<em>metainfo.xml</em>",id:"metainfoxml",level:3},{value:"Scripts",id:"scripts",level:4},{value:"Python",id:"python",level:4},{value:"OS Variant Scripts",id:"os-variant-scripts",level:5},{value:"Custom Actions",id:"custom-actions",level:4},{value:"Stack Changes",id:"stack-changes",level:5},{value:"UI Changes",id:"ui-changes",level:5},{value:"Configuration",id:"configuration",level:3},{value:"Adding new configs in a config-type",id:"adding-new-configs-in-a-config-type",level:4},{value:"UI - Categories",id:"ui---categories",level:4},{value:"UI - Enhanced Configs",id:"ui---enhanced-configs",level:4},{value:"Alerts",id:"alerts",level:3},{value:"Kerberos",id:"kerberos",level:3},{value:"Metrics",id:"metrics",level:3},{value:"Quick Links",id:"quick-links",level:3},{value:"Widgets",id:"widgets",level:3},{value:"Role Command Order",id:"role-command-order",level:3},{value:"Service Advisor",id:"service-advisor",level:3},{value:"<strong>Examples</strong>",id:"examples",level:4},{value:"Service Upgrade",id:"service-upgrade",level:3},{value:"Examples",id:"examples-1",level:4},{value:"Define Stack",id:"define-stack",level:2},{value:"Stack-Version Descriptor",id:"stack-version-descriptor",level:3},{value:"Stack Properties",id:"stack-properties",level:3},{value:"Services",id:"services",level:3},{value:"Reference <em>common-services</em>",id:"reference-common-services",level:4},{value:"Define Service",id:"define-service-1",level:4},{value:"Extend Service",id:"extend-service",level:4},{value:"Role Command Order",id:"role-command-order-1",level:3},{value:"Format",id:"format",level:4},{value:"Sections",id:"sections",level:4},{value:"Commands",id:"commands",level:4},{value:"Examples",id:"examples-2",level:4},{value:"Repositories",id:"repositories",level:3},{value:"Latest Builds",id:"latest-builds",level:4},{value:"Hooks",id:"hooks",level:3},{value:"Command Sub-Folders",id:"command-sub-folders",level:4},{value:"Configurations",id:"configurations",level:3},{value:"Stack Advisor",id:"stack-advisor",level:4},{value:"<strong>Examples</strong>",id:"examples-3",level:4},{value:"Properties",id:"properties",level:3},{value:"Widgets",id:"widgets-1",level:3},{value:"Kerberos",id:"kerberos-1",level:3},{value:"Stack Upgrades",id:"stack-upgrades",level:3},{value:"Rolling Upgrades",id:"rolling-upgrades",level:4},{value:"Express Upgrades",id:"express-upgrades",level:4},{value:"Configuration support in Ambari",id:"configuration-support-in-ambari",level:2}],l={toc:p};function m(e){let{components:a,...s}=e;return(0,n.kt)("wrapper",(0,r.Z)({},l,s,{components:a,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"how-to-define-stacks-and-services"},"How-To Define Stacks and Services"),(0,n.kt)("p",null,"Services managed by Ambari are defined in its ",(0,n.kt)("em",{parentName:"p"},"stacks")," folder ."),(0,n.kt)("p",null,"To define your own services and stacks to be managed by Ambari, follow the steps below."),(0,n.kt)("p",null,"There is also an example you can follow on how to ",(0,n.kt)("a",{parentName:"p",href:"/docs/next/ambari-design/stack-and-services/defining-a-custom-stack-and-services"},"create your custom stack and service"),"."),(0,n.kt)("p",null,"A stack is a collection of services. Multiple versions of a stack can be defined, each with its own set of services. Stacks in Ambari are defined in ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/tree/trunk/ambari-server/src/main/resources/stacks"},"ambari-server/src/main/resources/stacks ;"),"folder, which can be found at ",(0,n.kt)("strong",{parentName:"p"},"/var/lib/ambari-server/resources/stacks")," folder after install."),(0,n.kt)("p",null,"Services managed by a stack can be defined either in ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/tree/trunk/ambari-server/src/main/resources/common-services"},"ambari-server/src/main/resources/common-services"),"or ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/tree/trunk/ambari-server/src/main/resources/stacks"},"ambari-server/src/main/resources/stacks"),"folders. These folders after install can be found at ",(0,n.kt)("em",{parentName:"p"},"/var/lib/ambari-server/resources/common-services")," or ",(0,n.kt)("em",{parentName:"p"},"/var/lib/ambari-server/resources/stacks")," folders respectively."),(0,n.kt)("blockquote",null,(0,n.kt)("p",{parentName:"blockquote"},(0,n.kt)("strong",{parentName:"p"},"Question: When do I define service in ",(0,n.kt)("em",{parentName:"strong"},"common-services")," vs. ",(0,n.kt)("em",{parentName:"strong"},"stacks")," folders?"),"\nOne would define services in the ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/tree/trunk/ambari-server/src/main/resources/common-services"},"common-services"),"folder if there is possibility of the service being used in multiple stacks. For example, almost all stacks would need the HDFS service - so instead of redefining HDFS in each stack, the one defined in common-services is referenced .Likewise, if a service is never going to be shared, it can be defined in the ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/tree/trunk/ambari-server/src/main/resources/stacks"},"stacks"),"folder.Basically services defined in stacks folder are used by containment, whereas the ones defined in common-services are used by reference.")),(0,n.kt)("h2",{id:"define-service"},"Define Service"),(0,n.kt)("p",null,"Shown below is how to define a service in ",(0,n.kt)("em",{parentName:"p"},"common-services")," folder. The same approach can be taken when defining services in the ",(0,n.kt)("em",{parentName:"p"},"stacks")," folder, which will be discussed in the ",(0,n.kt)("em",{parentName:"p"},"Define Stack")," section."),(0,n.kt)("p",null,(0,n.kt)("img",{src:t(9230).Z,width:"1022",height:"654"})),(0,n.kt)("p",null,"Services ",(0,n.kt)("strong",{parentName:"p"},"MUST")," provide the main ",(0,n.kt)("em",{parentName:"p"},"metainfo.xml")," file which provides important metadata about the service."),(0,n.kt)("p",null,"Apart from that, other files can be provided to give more information about the service. More details about these files are provided below."),(0,n.kt)("p",null,"A service may also inherit from either a previous stack version or common services. For more information see the ",(0,n.kt)("a",{parentName:"p",href:"/docs/next/ambari-design/stack-and-services/stack-inheritance"},"Service Inheritance")," page."),(0,n.kt)("h3",{id:"metainfoxml"},(0,n.kt)("em",{parentName:"h3"},"metainfo.xml")),(0,n.kt)("p",null,"In the ",(0,n.kt)("em",{parentName:"p"},"metainfo.xml")," service descriptor, one can first define the service and its components."),(0,n.kt)("p",null,"Complete reference can be found in the ",(0,n.kt)("a",{parentName:"p",href:"/docs/next/ambari-design/stack-and-services/writing-metainfo"},"Writing metainfo.xml")," page."),(0,n.kt)("p",null,"A good reference implementation is the ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/metainfo.xml#L27"},"HDFS metainfo.xml"),"."),(0,n.kt)("blockquote",null,(0,n.kt)("p",{parentName:"blockquote"},(0,n.kt)("strong",{parentName:"p"},"Question: Is it possible to define multiple services in the same metainfo.xml?"),"\nYes. Though it is possible, it is discouraged to define multiple services in the same service folder.")),(0,n.kt)("p",null,"YARN and MapReduce2 are services that are defined together in the ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/tree/trunk/ambari-server/src/main/resources/common-services/YARN/2.1.0.2.0"},"YARN folder"),". Its ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/YARN/2.1.0.2.0/metainfo.xml"},"metainfo.xml")," defines both services."),(0,n.kt)("h4",{id:"scripts"},"Scripts"),(0,n.kt)("p",null,"With the components defined, we need to provide scripts which can handle the various stages of the service and component's lifecycle."),(0,n.kt)("p",null,"The scripts necessary to manage service and components are specified in the ",(0,n.kt)("em",{parentName:"p"},"metainfo.xml")," (",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/metainfo.xml#L35"},"HDFS"),")\nEach of these scripts should extend the ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/branch-2.2.1/ambari-common/src/main/python/resource_management/libraries/script/script.py"},"Script")," class which provides useful methods. Example: ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/package/scripts/namenode.py#L68"},"NameNode script")),(0,n.kt)("p",null,(0,n.kt)("img",{src:t(6145).Z,width:"1442",height:"950"})),(0,n.kt)("p",null,"These scripts should be provided in the __ folder."),(0,n.kt)("p",null,(0,n.kt)("img",{src:t(4331).Z,width:"632",height:"276"})),(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"},"package/scripts"),"\nFolder | Purpose\n-------|--------\n",(0,n.kt)("strong",{parentName:"p"},"package/scripts")," | Contains scripts invoked by Ambari. These scripts are loaded into the execution path with the correct environment.",(0,n.kt)("br",null),"Example: ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/tree/trunk/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/package/scripts"},"HDFS"),"\n",(0,n.kt)("strong",{parentName:"p"},"package/files")," | Contains files used by above scripts. Generally these are other scripts (bash, python, etc.) invoked as a separate process.",(0,n.kt)("br",null),"Example: ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/package/files/checkWebUI.py"},"checkWebUI.py")," is run in HDFS service-check to determine if Journal Nodes are available\n",(0,n.kt)("strong",{parentName:"p"},"package/templates")," | Template files used by above scripts to generate files on managed hosts. These are generally configuration files required by the service to operate.",(0,n.kt)("br",null),"Example: ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/package/templates/exclude_hosts_list.j2"},"exclude_hosts_list.j2")," which is used by scripts to generate ",(0,n.kt)("em",{parentName:"p"},"/etc/hadoop/conf/dfs.exclude")),(0,n.kt)("h4",{id:"python"},"Python"),(0,n.kt)("p",null,"Ambari by default supports Python scripts for management of service and components."),(0,n.kt)("p",null,"Component scripts should extend ",(0,n.kt)("inlineCode",{parentName:"p"},"resource_management.Script")," class and provide methods required for that component's lifecycle."),(0,n.kt)("p",null,"Taken from the page on ",(0,n.kt)("a",{parentName:"p",href:"/docs/next/ambari-design/stack-and-services/defining-a-custom-stack-and-services"},"how to create custom stack"),", the following methods are needed for MASTER, SLAVE and CLIENT components to go through their lifecycle."),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},"import sys\nfrom resource_management import Script\nclass Master(Script):\n  def install(self, env):\n    print 'Install the Sample Srv Master';\n  def stop(self, env):\n    print 'Stop the Sample Srv Master';\n  def start(self, env):\n    print 'Start the Sample Srv Master';\n  def status(self, env):\n    print 'Status of the Sample Srv Master';\n  def configure(self, env):\n    print 'Configure the Sample Srv Master';\nif __name__ == \"__main__\":\n  Master().execute()\n")),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},"import sys\nfrom resource_management import Script\nclass Slave(Script):\n  def install(self, env):\n    print 'Install the Sample Srv Slave';\n  def stop(self, env):\n    print 'Stop the Sample Srv Slave';\n  def start(self, env):\n    print 'Start the Sample Srv Slave';\n  def status(self, env):\n    print 'Status of the Sample Srv Slave';\n  def configure(self, env):\n    print 'Configure the Sample Srv Slave';\nif __name__ == \"__main__\":\n  Slave().execute()\n")),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},"import sys\nfrom resource_management import Script\nclass SampleClient(Script):\n  def install(self, env):\n    print 'Install the Sample Srv Client';\n  def configure(self, env):\n    print 'Configure the Sample Srv Client';\nif __name__ == \"__main__\":\n  SampleClient().execute()\n")),(0,n.kt)("p",null,"Ambari provides helpful Python libraries below which are useful in writing service scripts. For complete reference on these libraries visit the ",(0,n.kt)("a",{parentName:"p",href:"https://cwiki.apache.org/confluence/display/AMBARI/Ambari+Python+Libraries"},"Ambari Python Libraries")," page."),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"resource_management"),(0,n.kt)("li",{parentName:"ul"},"ambari_commons"),(0,n.kt)("li",{parentName:"ul"},"ambari_simplejson")),(0,n.kt)("h5",{id:"os-variant-scripts"},"OS Variant Scripts"),(0,n.kt)("p",null,"If the service is supported on multiple OSes which requires separate scripts, the base ",(0,n.kt)("em",{parentName:"p"},"resource_management.Script")," class can be extended with different ",(0,n.kt)("em",{parentName:"p"},"@OsFamilyImpl()")," annotations."),(0,n.kt)("p",null,"This allows for the separation of only OS specific methods of the component."),(0,n.kt)("p",null,"Example: ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/package/scripts/namenode.py#L126"},"NameNode default script"),", ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/package/scripts/namenode.py#L346"},"NameNode Windows script"),"."),(0,n.kt)("blockquote",null,(0,n.kt)("p",{parentName:"blockquote"},(0,n.kt)("strong",{parentName:"p"},"Examples"),"\nNameNode ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/package/scripts/hdfs_namenode.py#L93"},"Start"),", ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/package/scripts/hdfs_namenode.py#L208"},"Stop"),".")),(0,n.kt)("p",null,"DataNode ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/package/scripts/hdfs_datanode.py#L68"},"Start and Stop"),"."),(0,n.kt)("p",null,"HDFS ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/package/scripts/hdfs.py#L31"},"configurations persistence")),(0,n.kt)("h4",{id:"custom-actions"},"Custom Actions"),(0,n.kt)("p",null,"Sometimes services need to perform actions unique to that service which go beyond the default actions provided by Ambari (like ",(0,n.kt)("em",{parentName:"p"},"install")," , ",(0,n.kt)("em",{parentName:"p"},"start, stop, configure,")," etc.)."),(0,n.kt)("p",null,"Services can define such actions and expose them to the user in UI so that they can be easily invoked."),(0,n.kt)("p",null,"As an example, we show the ",(0,n.kt)("em",{parentName:"p"},"Rebalance HDFS")," custom action implemented by HDFS."),(0,n.kt)("h5",{id:"stack-changes"},"Stack Changes"),(0,n.kt)("ol",null,(0,n.kt)("li",{parentName:"ol"},(0,n.kt)("p",{parentName:"li"},(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/metainfo.xml#L49"},"Define custom command inside the ",(0,n.kt)("em",{parentName:"a"},"customCommands")," section")," of the component in ",(0,n.kt)("em",{parentName:"p"},"metainfo.xml"),".")),(0,n.kt)("li",{parentName:"ol"},(0,n.kt)("p",{parentName:"li"},(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/package/scripts/namenode.py#L273"},"Implement method with same name as custom command")," in script referenced from ",(0,n.kt)("em",{parentName:"p"},"metainfo.xml"),".")),(0,n.kt)("li",{parentName:"ol"},(0,n.kt)("p",{parentName:"li"},"If custom command does not have OS variants, it can be implemented in the same class that extends ",(0,n.kt)("em",{parentName:"p"},"resource_management.Script"))),(0,n.kt)("li",{parentName:"ol"},(0,n.kt)("p",{parentName:"li"},"If there are OS variants, different methods can be implemented in each class annotated by ",(0,n.kt)("em",{parentName:"p"},"@OsFamilyImpl(os_family=...)"),". ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/package/scripts/namenode.py#L273"},"Default rebalancehdfs"),",",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/package/scripts/namenode.py#L354"},"Windows rebalancehdfs"),"."))),(0,n.kt)("p",null,"This will provide ability by the backend to run the script on all managed hosts where the service is installed."),(0,n.kt)("h5",{id:"ui-changes"},"UI Changes"),(0,n.kt)("p",null,"No UI changes are necessary to see the custom action on the host page."),(0,n.kt)("p",null,"The action should show up in the host-component's list of actions. Any master-component actions will automatically show up on the service's action menu."),(0,n.kt)("p",null,"When the action is clicked in UI, the POST call is made automatically to trigger the script defined above."),(0,n.kt)("blockquote",null,(0,n.kt)("p",{parentName:"blockquote"},(0,n.kt)("strong",{parentName:"p"},"Question: How do I provide my own label and icon for the custom action in UI?"),"\nIn Ambari UI, add your component action to the ",(0,n.kt)("em",{parentName:"p"},"App.HostComponentActionMap")," object with custom icon and name. Ex: ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/branch-2.2.1/ambari-web/app/models/host_component.js#L351"},"REBALANCEHDFS"),".")),(0,n.kt)("h3",{id:"configuration"},"Configuration"),(0,n.kt)("p",null,"Configuration files for a service should be placed by default in the ",(0,n.kt)("em",{parentName:"p"}," ",(0,n.kt)("a",{parentName:"em",href:"https://github.com/apache/ambari/tree/branch-2.2.1/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/configuration"},"configuration"))," folder."),(0,n.kt)("p",null,"If a different named folder has to be used, the ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/common-services/YARN/2.1.0.2.0/metainfo.xml#L249"},"< ",(0,n.kt)("em",{parentName:"a"},"configuration-dir>"))," element can be used in ",(0,n.kt)("em",{parentName:"p"},"metainfo.xml")," to point to that folder."),(0,n.kt)("p",null,"The important sections of the metainfo.xml with regards to configurations are:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-xml"},'<?xml version="1.0"?>\n<metainfo>\n  <schemaVersion>2.0</schemaVersion>\n  <services>\n    <service>\n      <name>HDFS</name>\n      <displayName>HDFS</displayName>\n      <comment>Apache Hadoop Distributed File System</comment>\n      <version>2.1.0.2.0</version>\n      <components>\n        ...\n        <component>\n          <name>HDFS_CLIENT</name>\n          ...\n          <configFiles>\n            <configFile>\n              <type>xml</type>\n              <fileName>hdfs-site.xml</fileName>\n              <dictionaryName>hdfs-site</dictionaryName>\n            </configFile>\n            <configFile>\n              <type>xml</type>\n              <fileName>core-site.xml</fileName>\n              <dictionaryName>core-site</dictionaryName>\n            </configFile>\n            <configFile>\n              <type>env</type>\n              <fileName>log4j.properties</fileName>\n              <dictionaryName>hdfs-log4j,yarn-log4j</dictionaryName>\n            </configFile>                         \n            <configFile>\n              <type>env</type>\n              <fileName>hadoop-env.sh</fileName>\n              <dictionaryName>hadoop-env</dictionaryName>\n            </configFile>\n          </configFiles>\n          ...\n          <configuration-dependencies>\n             <config-type>core-site</config-type>\n             <config-type>hdfs-site</config-type>\n          </configuration-dependencies>\n        </component>\n          ...\n      </components>\n  \n      <configuration-dir>configuration</configuration-dir>\n      <configuration-dependencies>\n        <config-type>core-site</config-type>\n        <config-type>hdfs-site</config-type>\n        <config-type>hadoop-env</config-type>\n        <config-type>hadoop-policy</config-type>\n        <config-type>hdfs-log4j</config-type>\n        <config-type>ranger-hdfs-plugin-properties</config-type>\n        <config-type>ssl-client</config-type>\n        <config-type>ssl-server</config-type>\n        <config-type>ranger-hdfs-audit</config-type>\n        <config-type>ranger-hdfs-policymgr-ssl</config-type>\n        <config-type>ranger-hdfs-security</config-type>\n        <config-type>ams-ssl-client</config-type>\n      </configuration-dependencies>\n    </service>\n  </services>\n</metainfo>\n')),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},(0,n.kt)("strong",{parentName:"p"},"config-type")," - String representing a group of configurations. Example: ",(0,n.kt)("em",{parentName:"p"},"core-site, hdfs-site, yarn-site"),", etc. When configurations are saved in Ambari, they are persisted within a version of config-type which is immutable. If you change and save HDFS core-site configs 4 times, you will have 4 versions of config-type core-site. Also, when a service's configs are saved, only the changed config-types are updated.")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},(0,n.kt)("strong",{parentName:"p"},"configFiles")," - lists the config-files handled by the enclosing component")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},(0,n.kt)("strong",{parentName:"p"},"configFile")," - represents one config-file of a certain type"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},(0,n.kt)("strong",{parentName:"p"},"type")," - type of file based on which contents are generated differently"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"xml")," - XML file generated in Hadoop friendly format. Ex:",(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/configuration/hdfs-site.xml"},"hdfs-site.xml")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"env")," - Generally used for scripts where the content value is used as a template. The template has config-tags whose values are populated at runtime during file generation. Ex:",(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/configuration/hadoop-env.xml"},"hadoop-env.sh")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"properties")," - Generates property files where entries are in key=value format. Ex:",(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/FALCON/0.5.0.2.1/configuration/falcon-runtime.properties.xml"},"falcon-runtime.properties")))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},(0,n.kt)("strong",{parentName:"p"},"dictionaryName")," - Name of the config-type as which key/values of this config file will be stored")))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},(0,n.kt)("strong",{parentName:"p"},"configuration-dependencies")," - Lists the config-types on which this component or service depends on. One of the implications of this dependency is that whenever the config-type is updated, Ambari automatically marks the component or service as requiring restart. From the code section above, whenever ",(0,n.kt)("em",{parentName:"p"},"core-site")," is updated, both HDFS service as well as HDFS_CLIENT component will be marked as requiring restart.")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},(0,n.kt)("strong",{parentName:"p"},"configuration-dir")," - Directory where files listed in ",(0,n.kt)("em",{parentName:"p"},"configFiles")," will be. Optional. Default value is ",(0,n.kt)("em",{parentName:"p"},"configuration"),"."))),(0,n.kt)("h4",{id:"adding-new-configs-in-a-config-type"},"Adding new configs in a config-type"),(0,n.kt)("p",null,"There are a number of different parameters that can be specified to a config item when it is added to a config-type. These have been covered ",(0,n.kt)("a",{parentName:"p",href:"https://cwiki.apache.org/confluence/display/AMBARI/Configuration+support+in+Ambari"},"here"),"."),(0,n.kt)("h4",{id:"ui---categories"},"UI - Categories"),(0,n.kt)("p",null,"Configurations defined above show up in the service's ",(0,n.kt)("em",{parentName:"p"},"Configs")," page."),(0,n.kt)("p",null,"To customize categories and ordering of configurations in UI, the following files have to be updated."),(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"},"Create Category")," - Update the ",(0,n.kt)("em",{parentName:"p"}," ",(0,n.kt)("a",{parentName:"em",href:"https://github.com/apache/ambari/blob/trunk/ambari-web/app/models/stack_service.js#L226"},"ambari-web/app/models/stack_service.js"))," file to add your own service, along with your new categories."),(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"},"Use Category")," - To place configs inside a defined category, and specify an order in which configs are placed, add configs to ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-web/app/data/HDP2/site_properties.js"},"ambari-web/app/data/HDP2/site_properties.js")," file. In this file one can specify the category to use, and the index where a config should be placed. The stack folders in ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/tree/trunk/ambari-web/app/data"},"ambari-web/app/data")," are hierarchical and inherit from previous versions. The mapping of configurations into sections is defined here. Example ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-web/app/data/HDP2.2/hive_properties.js"},"Hive Categories"),", ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-web/app/data/HDP2.2/tez_properties.js"},"Tez Categories"),"."),(0,n.kt)("h4",{id:"ui---enhanced-configs"},"UI - Enhanced Configs"),(0,n.kt)("p",null,"The _Enhanced Configs_feature makes it possible for service providers to customize their service's configs to a great deal and determine which configs are prominently shown to user without making any UI code changes. Customization includes providing a service friendly layout, better controls (sliders, combos, lists, toggles, spinners, etc.), better validation (minimum, maximum, enums), automatic unit conversion (MB, GB, seconds, milliseconds, etc.), configuration dependencies and improved dynamic recommendations of default values."),(0,n.kt)("p",null,"A service provider can accomplish all the above just by changing their service definition in the ",(0,n.kt)("em",{parentName:"p"},"stacks"),"/folder."),(0,n.kt)("p",null,"Read more in the ",(0,n.kt)("em",{parentName:"p"}," ",(0,n.kt)("a",{parentName:"em",href:"https://cwiki.apache.org/confluence/display/AMBARI/Enhanced+Configs"},"Enhanced Configs"))," page"),(0,n.kt)("h3",{id:"alerts"},"Alerts"),(0,n.kt)("p",null,"Each service is capable of defining which alerts Ambari should track by providing an ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/alerts.json"},"alerts.json")," file."),(0,n.kt)("p",null,"Read more about Ambari Alerts framework ",(0,n.kt)("a",{parentName:"p",href:"https://cwiki.apache.org/confluence/display/AMBARI/Alerts"},"in the Alerts wiki page")," and the alerts.json format in the ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/branch-2.1/ambari-server/docs/api/v1/alert-definitions.md"},"Alerts definition documentation"),"."),(0,n.kt)("h3",{id:"kerberos"},"Kerberos"),(0,n.kt)("p",null,"Ambari is capable of enabling and disabling Kerberos for a cluster. To inform Ambari of the identities and configurations to be used for the service and its components, each service can provide a ",(0,n.kt)("em",{parentName:"p"},"kerberos.json")," file."),(0,n.kt)("p",null,"Read more about Kerberos support in the ",(0,n.kt)("em",{parentName:"p"}," ",(0,n.kt)("a",{parentName:"em",href:"https://cwiki.apache.org/confluence/display/AMBARI/Automated+Kerberizaton"},"Automated Kerberization"))," wiki page and the Kerberos descriptor in the ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/docs/security/kerberos/kerberos_descriptor.md"},"Kerberos Descriptor documentation"),"."),(0,n.kt)("h3",{id:"metrics"},"Metrics"),(0,n.kt)("p",null,"Ambari provides the ",(0,n.kt)("a",{parentName:"p",href:"https://cwiki.apache.org/confluence/display/AMBARI/Metrics"},'Ambari Metrics System ("AMS")'),"service for collecting, aggregating and serving Hadoop and system metrics in Ambari-managed clusters."),(0,n.kt)("p",null,"Each service can define which metrics AMS should collect and provide by defining a ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/metrics.json"},"metrics.json")," file."),(0,n.kt)("p",null,"You can read about the metrics.json file format in the ",(0,n.kt)("a",{parentName:"p",href:"https://cwiki.apache.org/confluence/display/AMBARI/Stack+Defined+Metrics"},"Stack Defined Metrics")," page."),(0,n.kt)("h3",{id:"quick-links"},"Quick Links"),(0,n.kt)("p",null,"A service can add a list of quick links to the Ambari web UI by adding metainfo to a text file following a predefined JSON format. Ambari server parses the quicklink JSON file and provides its content to the UI. So that Ambari web UI can calculate quick link URLs based on the information and populate the quicklinks drop-down list accordingly."),(0,n.kt)("p",null,"Read more about quick links JSON file design in the ",(0,n.kt)("a",{parentName:"p",href:"/docs/next/ambari-design/quick-links"},"Quick Links")," page."),(0,n.kt)("h3",{id:"widgets"},"Widgets"),(0,n.kt)("p",null,"Each service can define which widgets and heatmaps show up by default on the service summary page by defining a ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/widgets.json"},"widgets.json")," file."),(0,n.kt)("p",null,"You can read more about the widgets descriptor in the ",(0,n.kt)("a",{parentName:"p",href:"https://cwiki.apache.org/confluence/display/AMBARI/Enhanced+Service+Dashboard"},"Enhanced Service Dashboard")," page."),(0,n.kt)("h3",{id:"role-command-order"},"Role Command Order"),(0,n.kt)("p",null,"From Ambari 2.2, each service can define its own role command order by including the ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/role_command_order.json"},"role_command_order.json")," file in its service folder. The service should only specify the relationship of its components to other components. In other words, if a service only includes COMP_X, it should only list dependencies related to COMP_X. If when COMP_X starts it is dependent on the NameNode start and when the NameNode stops it should wait for COMP_X to stop, the following would be included in the role command order:"),(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"},"Example service role_command_order.json")),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-json"},'"COMP_X-START": ["NAMENODE-START"],\n    "NAMENODE-STOP": ["COMP_X-STOP"]\n')),(0,n.kt)("p",null,"The entries in the service's role command order will be merged with the role command order defined in the stack. For example, since the stack already has a dependency for NAMENODE-STOP, in the example above COMP_X-STOP would be added to the rest of the NAMENODE-STOP dependencies and in addition the COMP_X-START dependency on NAMENODE-START would just be added as a new dependency."),(0,n.kt)("p",null,"For more details on role command order, see the ",(0,n.kt)("a",{parentName:"p",href:"https://cwiki.apache.org/confluence/display/AMBARI/How-To+Define+Stacks+and+Services#How-ToDefineStacksandServices-RoleCommandOrder"},"Role Command Order")," section below."),(0,n.kt)("h3",{id:"service-advisor"},"Service Advisor"),(0,n.kt)("p",null,"From Ambari 2.4, each service can choose to define its own service advisor rather than define the details of its configuration and layout in the stack advisor. This is particularly useful for custom services which are not defined in the stack. Ambari provides the ",(0,n.kt)("em",{parentName:"p"},"Service Advisor")," capability where a service can write a Python script named ",(0,n.kt)("em",{parentName:"p"},"service-advisor.py")," in their service folder. This folder can be in the stack's services directory where the service is defined or can be inherited from the service definition in common-services or elsewhere. Example: ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/tree/trunk/ambari-server/src/main/resources/common-services/HAWQ/2.0.0"},"common-services/HAWQ/2.0.0"),"."),(0,n.kt)("p",null,"Unlike the Stack-advisor scripts, the service-advisor scripts do not automatically extend the parent service's service-advisor scripts. The service-advisor script needs to explicitly extend their parent's service service-advisor script. The following code sample shows how you would refer to a parent's service_advisor.py. In this case it is extending the root service-advisor.py file in the resources/stacks directory."),(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"},"Sample service-advisor.py file inheritance")),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},"SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))\nSTACKS_DIR = os.path.join(SCRIPT_DIR, '../../../stacks/')\nPARENT_FILE = os.path.join(STACKS_DIR, 'service_advisor.py')\n\ntry:\n  with open(PARENT_FILE, 'rb') as fp:\n    service_advisor = imp.load_module('service_advisor', fp, PARENT_FILE, ('.py', 'rb', imp.PY_SOURCE))\nexcept Exception as e:\n  traceback.print_exc()\n  print \"Failed to load parent\"\n\nclass HAWQ200ServiceAdvisor(service_advisor.ServiceAdvisor):\n")),(0,n.kt)("p",null,"Like the stack advisors, service advisors provide information on 4 important aspects:"),(0,n.kt)("ol",null,(0,n.kt)("li",{parentName:"ol"},"Recommend layout of the service on cluster"),(0,n.kt)("li",{parentName:"ol"},"Recommend service configurations"),(0,n.kt)("li",{parentName:"ol"},"Validate layout of the service on cluster"),(0,n.kt)("li",{parentName:"ol"},"Validate service configurations")),(0,n.kt)("p",null,"By providing the service-advisor.py file, one can control dynamically each of the above for the service."),(0,n.kt)("p",null,"The main interface for the service-advisor scripts contains documentation on how each of the above are called, and what data is provided."),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},'class ServiceAdvisor(DefaultStackAdvisor):\n"""\n  Abstract class implemented by all service advisors.\n\n"""\n\n"""\n  If any components of the service should be colocated with other services,\n  this is where you should set up that layout.  Example:\n\n    # colocate HAWQSEGMENT with DATANODE, if no hosts have been allocated for HAWQSEGMENT\n    hawqSegment = [component for component in serviceComponents if component["StackServiceComponents"]["component_name"] == "HAWQSEGMENT"][0]\n    if not self.isComponentHostsPopulated(hawqSegment):\n      for hostName in hostsComponentsMap.keys():\n        hostComponents = hostsComponentsMap[hostName]\n        if {"name": "DATANODE"} in hostComponents and {"name": "HAWQSEGMENT"} not in hostComponents:\n          hostsComponentsMap[hostName].append( { "name": "HAWQSEGMENT" } )\n        if {"name": "DATANODE"} not in hostComponents and {"name": "HAWQSEGMENT"} in hostComponents:\n          hostComponents.remove({"name": "HAWQSEGMENT"})\n"""\n  def colocateService(self, hostsComponentsMap, serviceComponents):\n    pass\n\n"""\n  Any configuration recommendations for the service should be defined in this function.\n\n  This should be similar to any of the recommendXXXXConfigurations functions in the stack_advisor.py\n  such as recommendYARNConfigurations().\n\n"""\n  def getServiceConfigurationRecommendations(self, configurations, clusterSummary, services, hosts):\n    pass\n\n"""\n  Returns an array of Validation objects about issues with the hostnames to which components are assigned.\n\n  This should detect validation issues which are different than those the stack_advisor.py detects.\n\n  The default validations are in stack_advisor.py getComponentLayoutValidations function.\n\n"""\n  def getServiceComponentLayoutValidations(self, services, hosts):\n    return []\n\n"""\n  Any configuration validations for the service should be defined in this function.\n\n  This should be similar to any of the validateXXXXConfigurations functions in the stack_advisor.py\n  such as validateHDFSConfigurations.\n\n"""\n  def getServiceConfigurationsValidationItems(self, configurations, recommendedDefaults, services, hosts):\n    return []\n')),(0,n.kt)("h4",{id:"examples"},(0,n.kt)("strong",{parentName:"h4"},"Examples")),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/service_advisor.py#L51"},"Service Advisor interface")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/HAWQ/2.0.0/service_advisor.py"},"HAWQ 2.0.0 Service Advisor implementation")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/PXF/3.0.0/service_advisor.py"},"PXF 3.0.0 Service Advisor implementation"))),(0,n.kt)("h3",{id:"service-upgrade"},"Service Upgrade"),(0,n.kt)("p",null,"From Ambari 2.4, each service can now define its upgrade within its service definition. This is particularly useful for custom services which no longer need to modify the stack's upgrade-packs in order to integrate themselves into the ",(0,n.kt)("a",{parentName:"p",href:"https://cwiki.apache.org/confluence/display/AMBARI/How-To+Define+Stacks+and+Services#How-ToDefineStacksandServices-StackUpgrades"},"cluster upgrade"),"."),(0,n.kt)("p",null,"Each service can define ",(0,n.kt)("em",{parentName:"p"},"upgrade-packs"),", which are XML files describing the upgrade process of that particular service and how the upgrade pack relates to the overall stack upgrade-packs. These ",(0,n.kt)("em",{parentName:"p"},"upgrade-pack")," XML files are placed in the service's ",(0,n.kt)("em",{parentName:"p"},"upgrades/")," folder in separate sub-folders specific to the stack-version they are meant to extend. Some examples of this can be seen in the testing code."),(0,n.kt)("h4",{id:"examples-1"},"Examples"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/test/resources/stacks/HDP/2.0.5/services/HDFS/upgrades/"},"Upgrades folder")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/test/resources/stacks/HDP/2.0.5/services/HDFS/upgrades/HDP/2.2.0/upgrade_test_15388.xml"},"Upgrade-pack XML"))),(0,n.kt)("p",null,"Each upgrade-pack that the service defines should match the file name of the service defined by a particular stack version. For example in the testing code, HDP 2.2.0 had an ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/test/resources/stacks/HDP/2.2.0/upgrades/upgrade_test_15388.xml"},"upgrade_test_15388.xml")," upgrade-pack. The HDFS service defined an extension to that upgrade pack ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/test/resources/stacks/HDP/2.0.5/services/HDFS/upgrades/HDP/2.2.0/upgrade_test_15388.xml"},"HDP/2.0.5/services/HDFS/upgrades/HDP/2.2.0/upgrade_test_15388.xml"),". In this case the upgrade-pack was defined in the HDP/2.0.5 stack. The upgrade-pack is an extension to HDP/2.2.0 because it is defined in upgrade/HDP/2.2.0 directory. Finally the name of the service's extension to the upgrade-pack upgrade_test_15388.xml matches the name of the upgrade-pack in HDP/2.2.0/upgrades."),(0,n.kt)("p",null,"The file format for the service is much the same as that of the stack. The target, target-stack and type attributes should all be the same as the stack's upgrade-pack. The service is able to add its own prerequisite checks."),(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"},"General Attributes and Prerequisite Checks")),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},'<upgrade xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">\n  <target>2.4.*</target>\n  <target-stack>HDP-2.4.0</target-stack>\n  <type>ROLLING</type>\n  <prerequisite-checks>\n    <check>org.apache.ambari.server.checks.FooCheck</check>\n  </prerequisite-checks>\n')),(0,n.kt)("p",null,"The order section of the upgrade-pack, consists of group elements just like the stack's upgrade-pack.  The key difference is defining how these groups relate to groups in the stack's upgrade pack or other service upgrade-packs.  In the first example we are referencing the PRE_CLUSTER group and adding a new execute-stage for the service FOO.  The entry is supposed to be added after the execute-stage for HDFS based on the ",(0,n.kt)("inlineCode",{parentName:"p"},"<add-after-group-entry>")," tag."),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-xml"},'<order>\n  <group xsi:type="cluster" name="PRE_CLUSTER" title="Pre {{direction.text.proper}}">\n    <add-after-group-entry>HDFS</add-after-group-entry>\n    <execute-stage service="FOO" component="BAR" title="Backup FOO">\n      <task xsi:type="manual">\n        <message>Back FOO up.</message>\n      </task>\n    </execute-stage>\n  </group>\n\n')),(0,n.kt)("p",null,"The same syntax can be used to order other sections like service check priorities and group services."),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-xml"},'<group name="SERVICE_CHECK1" title="All Service Checks" xsi:type="service-check">\n  <add-after-group-entry>ZOOKEEPER</add-after-group-entry>\n  <priority>\n    <service>HBASE</service>\n  </priority>\n</group>\n \n<group name="CORE_MASTER" title="Core Masters">\n  <add-after-group-entry>YARN</add-after-group-entry>\n  <service name="HBASE">\n    <component>HBASE_MASTER</component>\n  </service>\n</group>\n')),(0,n.kt)("p",null,"It is also possible to add new groups and order them after other groups in the stack's upgrade-packs. In the following example, we are adding the FOO group after the HIVE group using the add-after-group tag."),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-xml"},'<group name="FOO" title="Foo">\n  <add-after-group>HIVE</add-after-group>\n  <skippable>true</skippable>\n  <allow-retry>false</allow-retry>\n  <service name="FOO">\n    <component>BAR</component>\n  </service>\n</group>\n')),(0,n.kt)("p",null,"You could also include both the add-after-group and the add-after-group-entry tags in the same group. This will create a new group if it doesn't already exist and will order it after the add-after-group's group name. The add-after-group-entry will determine the internal ordering of that group's services, priorities or execute stages."),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-xml"},'<group name="FOO" title="Foo">\n  <add-after-group>HIVE</add-after-group>\n  <add-after-group-entry>FOO</add-after-group-entry>\n  <skippable>true</skippable>\n  <allow-retry>false</allow-retry>\n  <service name="FOO2">\n    <component>BAR2</component>\n  </service>\n</group>\n')),(0,n.kt)("p",null,"The processing section of the upgrade-pack remains the same as what it would be in the stack's upgrade-pack."),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-xml"},'   <processing>\n    <service name="FOO">\n      <component name="BAR">\n        <upgrade>\n          <task xsi:type="restart-task" />\n        </upgrade>\n      </component>\n      <component name="BAR2">\n        <upgrade>\n          <task xsi:type="restart-task" />\n        </upgrade>\n      </component>\n    </service>\n  </processing>\n')),(0,n.kt)("h2",{id:"define-stack"},"Define Stack"),(0,n.kt)("p",null,"A stack is a versioned collection of services. Each stack is a folder is defined in ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/tree/trunk/ambari-server/src/main/resources/stacks"},"ambari-server/src/main/resources/stacks")," source. Once installed, these stack definitions are available on the ambari-server machine at ",(0,n.kt)("em",{parentName:"p"},"/var/lib/ambari-server/resources/stacks"),"."),(0,n.kt)("p",null,"Each stack folder contains one sub-folder per version of the stack. Some of these stack-versions are active while some are not. Each stack-version includes services which are either referenced from ",(0,n.kt)("em",{parentName:"p"},"common-services"),", or defined inside the stack-version's ",(0,n.kt)("em",{parentName:"p"},"services")," folder."),(0,n.kt)("p",null,(0,n.kt)("img",{src:t(9926).Z,width:"766",height:"792"})),(0,n.kt)("p",null,"Example: ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/tree/trunk/ambari-server/src/main/resources/stacks/HDP"},"HDP stack"),". ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/tree/trunk/ambari-server/src/main/resources/stacks/HDP/2.4"},"HDP-2.4 stack version"),"."),(0,n.kt)("h3",{id:"stack-version-descriptor"},"Stack-Version Descriptor"),(0,n.kt)("p",null,"Each stack-version should provide a ",(0,n.kt)("em",{parentName:"p"},"metainfo.xml")," (Example: ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.3/metainfo.xml"},"HDP-2.3"),", ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.4/metainfo.xml"},"HDP-2.4"),") descriptor file which describes the following about this stack-version:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-xml"},"<metainfo>\n    <versions>\n      <active>true</active>\n    </versions>\n    <extends>2.3</extends>\n    <minJdk>1.7</minJdk>\n    <maxJdk>1.8</maxJdk>\n</metainfo>\n")),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},(0,n.kt)("strong",{parentName:"p"},"versions/active")," - Whether this stack-version is still available for install. If not available, this version will not show up in UI during install.")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},(0,n.kt)("strong",{parentName:"p"},"extends")," - The stack-version in this stack that is being extended. Extended stack-versions inherit services along with almost all aspects of the parent stack-version.")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},(0,n.kt)("strong",{parentName:"p"},"minJdk")," - Minimum JDK with which this stack-version is supported. Users are warned during installer wizard if the JDK used by Ambari is lower than this version.")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},(0,n.kt)("strong",{parentName:"p"},"maxJdk")," - Maximum JDK with which this stack-version is supported. Users are warned during installer wizard if the JDK used by Ambari is greater than this version."))),(0,n.kt)("h3",{id:"stack-properties"},"Stack Properties"),(0,n.kt)("p",null,"The stack must contain or inherit a properties directory which contains two files: ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/properties/stack_features.json"},"stack_features.json")," and ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/properties/stack_tools.json"},"stack_tools.json"),". This ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/tree/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/properties"},"directory")," is new in Ambari 2.4."),(0,n.kt)("p",null,"The stack_features.json contains a list of features that are included in Ambari and allows the stack to specify which versions of the stack include those features. The list of features are determined by the particular Ambari release. The reference list for a particular Ambari version should be found in the ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/branch-2.4/ambari-server/src/main/resources/stacks/HDP/2.0.6/properties/stack_features.json"},"HDP/2.0.6/properties/stack_features.json")," in the branch for that Ambari release. Each feature has a name and description and the stack can provide the minimum and maximum version where that feature is supported."),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-json"},'{\n\n"stack_features": [\n\n{\n\n"name": "snappy",\n\n"description": "Snappy compressor/decompressor support",\n\n"min_version": "2.0.0.0",\n\n"max_version": "2.2.0.0"\n\n},\n\n...\n\n}\n')),(0,n.kt)("p",null,"The stack_tools.json includes the name and location where the stack_selector and conf_selector tools are installed."),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-json"},'{\n\n"stack_selector": ["hdp-select", "/usr/bin/hdp-select", "hdp-select"],\n\n"conf_selector": ["conf-select", "/usr/bin/conf-select", "conf-select"]\n\n}\n')),(0,n.kt)("p",null,"Any custom stack must include these two JSON files. For further information see the ",(0,n.kt)("a",{parentName:"p",href:"/docs/next/ambari-design/stack-and-services/stack-properties"},"Stack Properties")," wiki page."),(0,n.kt)("h3",{id:"services"},"Services"),(0,n.kt)("p",null,"Each stack-version includes services which are either referenced from ",(0,n.kt)("em",{parentName:"p"},"common-services"),", or defined inside the stack-version's ",(0,n.kt)("em",{parentName:"p"},"services")," folder."),(0,n.kt)("p",null,"Services are defined in ",(0,n.kt)("em",{parentName:"p"},"common-services")," if they will be shared across multiple stacks. If they will never be shared, then they can be defined inside the stack-version."),(0,n.kt)("h4",{id:"reference-common-services"},"Reference ",(0,n.kt)("em",{parentName:"h4"},"common-services")),(0,n.kt)("p",null,"To reference a service from common-services, the service descriptor file should use the < ",(0,n.kt)("em",{parentName:"p"},"extends>")," element. (Example: ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/services/HDFS/metainfo.xml"},"HDFS in HDP-2.0.6"),")"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-xml"},"<metainfo>\n  <schemaVersion>2.0</schemaVersion>\n  <services>\n    <service>\n      <name>HDFS</name>\n      <extends>common-services/HDFS/2.1.0.2.0</extends>\n    </service>\n  </services>\n</metainfo>\n")),(0,n.kt)("h4",{id:"define-service-1"},"Define Service"),(0,n.kt)("p",null,"In exactly the same format as services defined in ",(0,n.kt)("em",{parentName:"p"},"common-services"),", a new service can be defined inside the ",(0,n.kt)("em",{parentName:"p"},"services")," folder."),(0,n.kt)("p",null,"Examples:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/tree/trunk/ambari-server/src/main/resources/stacks/BIGTOP/0.8/services/HDFS"},"HDFS in BIGTOP-0.8")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/tree/trunk/ambari-server/src/main/resources/stacks/HDP/2.3.GlusterFS/services/GLUSTERFS"},"GlusterFS in HDP-2.3.GlusterFS"))),(0,n.kt)("h4",{id:"extend-service"},"Extend Service"),(0,n.kt)("p",null,"When a stack-version extends another stack-version, it inherits all details of the parent service. It is also free to override and remove any portion of the inherited service definition."),(0,n.kt)("p",null,"Examples:"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"HDP-2.3 / HDFS -",(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.3/services/HDFS/metainfo.xml"},"Adding NFS_GATEWAY component, updating service version and OS specific packages")),(0,n.kt)("li",{parentName:"ul"},"HDP-2.2 / Storm -",(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.2/services/STORM/metainfo.xml"},"Deleting STORM_REST_API component, updating service version and OS specific packages")),(0,n.kt)("li",{parentName:"ul"},"HDP-2.3 / YARN -",(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.3/services/YARN/configuration/capacity-scheduler.xml"},"Deleting YARN node-label configuration from capacity-scheduler.xml")),(0,n.kt)("li",{parentName:"ul"},"HDP-2.3 / Kafka -",(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.3/services/KAFKA/alerts.json"},"Add Kafka Broker Process alert"))),(0,n.kt)("h3",{id:"role-command-order-1"},"Role Command Order"),(0,n.kt)("p",null,(0,n.kt)("em",{parentName:"p"},(0,n.kt)("strong",{parentName:"em"},"Role"))," is another name for ",(0,n.kt)("strong",{parentName:"p"},"Component")," (Ex: NAMENODE, DATANODE, RESOURCEMANAGER, HBASE_MASTER, etc.)"),(0,n.kt)("p",null,"As the name implies, it is possible to tell Ambari about the order in which commands should be run for the components defined in your stack."),(0,n.kt)("p",null,'For example: "',(0,n.kt)("em",{parentName:"p"},"ZooKeeper Server")," should be started before starting ",(0,n.kt)("em",{parentName:"p"},"NameNode"),'". Or "',(0,n.kt)("em",{parentName:"p"},"HBase Master")," should be started only after ",(0,n.kt)("em",{parentName:"p"},"NameNode")," and ",(0,n.kt)("em",{parentName:"p"},"DataNodes"),' are started".'),(0,n.kt)("p",null,"This can be specified by including the ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/role_command_order.json"},"role_command_order.json")," file in the stack-version folder."),(0,n.kt)("h4",{id:"format"},"Format"),(0,n.kt)("p",null,"Specified in JSON format, the file contains a JSON object with top-level keys being either section names or comments Ex: ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/role_command_order.json"},"HDP-2.0.6"),"."),(0,n.kt)("p",null,"Inside each section object, the key describes the dependent component-action, and the value lists the component-actions which should be done before it."),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "_comment": "Section 1 comment",\n  "section_name_1": {\n    "_comment": "Section containing role command orders",\n    "-": ["-", "-"],\n    "-": ["-"],\n    ...\n\n  },\n  "_comment": "Next section comment",\n  ...\n\n}\n')),(0,n.kt)("h4",{id:"sections"},"Sections"),(0,n.kt)("p",null,"Ambari uses the below sections only:"),(0,n.kt)("table",null,(0,n.kt)("thead",{parentName:"table"},(0,n.kt)("tr",{parentName:"thead"},(0,n.kt)("th",{parentName:"tr",align:null},"Section Name"),(0,n.kt)("th",{parentName:"tr",align:null},"When Used"))),(0,n.kt)("tbody",{parentName:"table"},(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"general_deps"),(0,n.kt)("td",{parentName:"tr",align:null},"Command orders are applied in all situations")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"optional_glusterfs"),(0,n.kt)("td",{parentName:"tr",align:null},"Command orders are applied when cluster has instance of GLUSTERFS service")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"optional_no_glusterfs"),(0,n.kt)("td",{parentName:"tr",align:null},"Command orders are applied when cluster does not have instance of GLUSTERFS service")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"namenode_optional_ha"),(0,n.kt)("td",{parentName:"tr",align:null},"Command orders are applied when HDFS service is installed and JOURNALNODE component exists (HDFS HA is enabled)")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"resourcemanager_optional_ha"),(0,n.kt)("td",{parentName:"tr",align:null},"Command orders are applied when YARN service is installed and multiple RESOURCEMANAGER host-components exist (YARN HA is enabled)")))),(0,n.kt)("h4",{id:"commands"},"Commands"),(0,n.kt)("p",null,"Commands currently supported by Ambari are"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"INSTALL"),(0,n.kt)("li",{parentName:"ul"},"UNINSTALL"),(0,n.kt)("li",{parentName:"ul"},"START"),(0,n.kt)("li",{parentName:"ul"},"RESTART"),(0,n.kt)("li",{parentName:"ul"},"STOP"),(0,n.kt)("li",{parentName:"ul"},"EXECUTE"),(0,n.kt)("li",{parentName:"ul"},"ABORT"),(0,n.kt)("li",{parentName:"ul"},"UPGRADE"),(0,n.kt)("li",{parentName:"ul"},"SERVICE_CHECK"),(0,n.kt)("li",{parentName:"ul"},"CUSTOM_COMMAND"),(0,n.kt)("li",{parentName:"ul"},"ACTIONEXECUTE")),(0,n.kt)("h4",{id:"examples-2"},"Examples"),(0,n.kt)("table",null,(0,n.kt)("thead",{parentName:"table"},(0,n.kt)("tr",{parentName:"thead"},(0,n.kt)("th",{parentName:"tr",align:null},"Role Command Order"),(0,n.kt)("th",{parentName:"tr",align:null},"Explanation"))),(0,n.kt)("tbody",{parentName:"table"},(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},'"HIVE_METASTORE-START": ','["MYSQL_SERVER-START", "NAMENODE-START"]'),(0,n.kt)("td",{parentName:"tr",align:null},"Start MySQL and NameNode components before starting Hive Metastore")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},'"MAPREDUCE_SERVICE_CHECK-SERVICE_CHECK": ','["NODEMANAGER-START", "RESOURCEMANAGER-START"]',","),(0,n.kt)("td",{parentName:"tr",align:null},"MapReduce service check needs ResourceManager and NodeManagers started")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},'"ZOOKEEPER_SERVER-STOP" : ','["HBASE_MASTER-STOP", "HBASE_REGIONSERVER-STOP", "METRICS_COLLECTOR-STOP"]',","),(0,n.kt)("td",{parentName:"tr",align:null},"Before stopping ZooKeeper servers, make sure HBase Masters, HBase RegionServers and AMS Metrics Collector are stopped.")))),(0,n.kt)("h3",{id:"repositories"},"Repositories"),(0,n.kt)("p",null,"Each stack-version can provide the location of package repositories to use, by providing a ",(0,n.kt)("em",{parentName:"p"},"repos/repoinfo.xml")," (Ex: ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/repos/repoinfo.xml"},"HDP-2.0.6"),")\nThe ",(0,n.kt)("em",{parentName:"p"},"repoinfo.xml")," file contains repositories grouped by operating systems. Each OS specifies a list of repositories that are shown to the user when the stack-version is selected for install."),(0,n.kt)("p",null,"These repositories are used in conjunction with the ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/metainfo.xml#L161"},(0,n.kt)("em",{parentName:"a"},"packages")," defined in a service's metainfo.xml")," to install appropriate bits on the system."),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-xml"},'<reposinfo>\n  <os family="redhat6">\n    <repo>\n      <baseurl>http://public-repo-1.hortonworks.com/HDP/centos6/2.x/updates/2.0.6.1</baseurl>\n      <repoid>HDP-2.0.6</repoid>\n      <reponame>HDP</reponame>\n    </repo>\n    <repo>\n      <baseurl>http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.17/repos/centos6</baseurl>\n      <repoid>HDP-UTILS-1.1.0.17</repoid>\n      <reponame>HDP-UTILS</reponame>\n    </repo>\n  </os>\n<reposinfo>\n')),(0,n.kt)("p",null,"baseurl- URL of the RPM repository where provided ",(0,n.kt)("em",{parentName:"p"},"repoid")," can be found\n",(0,n.kt)("strong",{parentName:"p"},"repoid")," - Repo ID to use that are hosted at _baseurl\n",(0,n.kt)("strong",{parentName:"p"},"reponame")," - Display name for the repo being used."),(0,n.kt)("h4",{id:"latest-builds"},"Latest Builds"),(0,n.kt)("p",null,"Though repository base URL is capable of providing updates to a particular repo, it has to be defined at build time. This could be an issue later when the repository changes location, or update builds are hosted at a different site."),(0,n.kt)("p",null,"For such scenarios, a stack-version can provide the location of a JSON file which can provide details of other repo URLs to use."),(0,n.kt)("p",null,"Example: ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.3/repos/repoinfo.xml"},"HDP-2.3 repoinfo.xml uses"),", which then points to alternate repository URLs where latest builds can be found:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-json"},'{\n    ...\n\n    "HDP-2.3":{\n        "latest":{\n            "centos6":"http://s3.amazonaws.com/dev.hortonworks.com/HDP/centos6/2.x/BUILDS/2.3.6.0-3586/",\n            "centos7":"http://s3.amazonaws.com/dev.hortonworks.com/HDP/centos7/2.x/BUILDS/2.3.6.0-3586/",\n            "debian6":"http://s3.amazonaws.com/dev.hortonworks.com/HDP/debian6/2.x/BUILDS/2.3.6.0-3586/",\n            "debian7":"http://s3.amazonaws.com/dev.hortonworks.com/HDP/debian7/2.x/BUILDS/2.3.6.0-3586/",\n            "suse11":"http://s3.amazonaws.com/dev.hortonworks.com/HDP/suse11sp3/2.x/BUILDS/2.3.6.0-3586/",\n            "ubuntu12":"http://s3.amazonaws.com/dev.hortonworks.com/HDP/ubuntu12/2.x/BUILDS/2.3.6.0-3586/",\n            "ubuntu14":"http://s3.amazonaws.com/dev.hortonworks.com/HDP/ubuntu14/2.x/BUILDS/2.3.6.0-3586/"\n        }\n    },\n    ...\n\n}\n')),(0,n.kt)("h3",{id:"hooks"},"Hooks"),(0,n.kt)("p",null,"A stack-version could have very basic and common instructions that need to be run before or after certain Ambari commands, across all services."),(0,n.kt)("p",null,"Instead of duplicating this code across all service scripts and asking users to worry about them, Ambari provides the ",(0,n.kt)("em",{parentName:"p"},"Hooks")," ability where common before and after code can be pulled away into the ",(0,n.kt)("em",{parentName:"p"},"hooks")," folder. (Ex: ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/tree/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/hooks"},"HDP-2.0.6"),")"),(0,n.kt)("p",null,(0,n.kt)("img",{src:t(1068).Z,width:"766",height:"792"})),(0,n.kt)("h4",{id:"command-sub-folders"},"Command Sub-Folders"),(0,n.kt)("p",null,"The general naming pattern for hooks sub-folders is ",(0,n.kt)("inlineCode",{parentName:"p"},'"<before|after>-<ANY|<CommandName>>"'),".\nWhat this means is that the scripts/hook.py file under the sub-folder is run either before or after the command."),(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"},"Examples:")),(0,n.kt)("table",null,(0,n.kt)("thead",{parentName:"table"},(0,n.kt)("tr",{parentName:"thead"},(0,n.kt)("th",{parentName:"tr",align:null},"Sub-Folder"),(0,n.kt)("th",{parentName:"tr",align:null},"Purpose"),(0,n.kt)("th",{parentName:"tr",align:null},"Example"))),(0,n.kt)("tbody",{parentName:"table"},(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"before-START"),(0,n.kt)("td",{parentName:"tr",align:null},"Hook script called before START command is run on any component of the stack-version."),(0,n.kt)("td",{parentName:"tr",align:null},(0,n.kt)("a",{parentName:"td",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/hooks/before-START/scripts/hook.py#L30"},"HDP-2.0.6"),(0,n.kt)("br",null),"sets up Hadoop log and pid directories",(0,n.kt)("br",null),"creates Java Home symlink",(0,n.kt)("br",null),"Creates /etc/hadoop/conf/topology_script.py",(0,n.kt)("br",null),"etc.")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"before-INSTALL"),(0,n.kt)("td",{parentName:"tr",align:null},"Hook script called before installing of any component of the stack-version"),(0,n.kt)("td",{parentName:"tr",align:null},(0,n.kt)("a",{parentName:"td",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/hooks/before-INSTALL/scripts/hook.py#L33"},"HDP-2.0.6"),(0,n.kt)("br",null),"Creates repo files in /etc/yum.repos.d",(0,n.kt)("br",null),"Installs basic packages like curl, unzip, etc.")))),(0,n.kt)("p",null,"Based on the commands currently supported by Ambari, the following sub-folders can be created based on necessity"),(0,n.kt)("table",null,(0,n.kt)("thead",{parentName:"table"},(0,n.kt)("tr",{parentName:"thead"},(0,n.kt)("th",{parentName:"tr",align:null},"Prefix"),(0,n.kt)("th",{parentName:"tr",align:null},"-"),(0,n.kt)("th",{parentName:"tr",align:null},"Command"))),(0,n.kt)("tbody",{parentName:"table"},(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"before"),(0,n.kt)("td",{parentName:"tr",align:null},"-"),(0,n.kt)("td",{parentName:"tr",align:null},"INSTALL UNINSTALL START RESTART STOP")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"after"),(0,n.kt)("td",{parentName:"tr",align:null},"-"),(0,n.kt)("td",{parentName:"tr",align:null},"EXECUTE ABORT UPGRADE  SERVICE_CHECK  ",(0,n.kt)("inlineCode",{parentName:"td"},"<custom_command>"),"-Custom commands specified by the user like the DECOMMISSION or REBALANCEHDFS commands specified by HDFS")))),(0,n.kt)("p",null,"The ",(0,n.kt)("em",{parentName:"p"},"scripts/hook.py")," script should import ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-common/src/main/python/resource_management/libraries/script/hook.py"},"resource_management.libraries.script.hook")," module and extend the Hook class"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},'from resource_management.libraries.script.hook import Hook\n\nclass CustomHook(Hook):\n  def hook(self, env):\n    # Do custom work\n\nif __name__ == "__main__":\n  CustomHook().execute()\n')),(0,n.kt)("h3",{id:"configurations"},"Configurations"),(0,n.kt)("p",null,"Though most configurations are set at the service level, there can be configurations which apply across all services to indicate the state of the cluster installed with this stack."),(0,n.kt)("p",null,"For example, things like ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/configuration/cluster-env.xml#L25"},'"is security enabled?"'),", ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/configuration/cluster-env.xml#L46"},'"what user runs smoke tests?"')," etc."),(0,n.kt)("p",null,"Such configurations can be defined in the ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/tree/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/configuration"},"configuration folder")," of the stack. They are available for access just like the service-level configs."),(0,n.kt)("h4",{id:"stack-advisor"},"Stack Advisor"),(0,n.kt)("p",null,"With each stack containing multiple complex services, it becomes necessary to dynamically determine how the services are laid out on the cluster, and for determining values of certain configurations."),(0,n.kt)("p",null,"Ambari provides the ",(0,n.kt)("em",{parentName:"p"},"Stack Advisor")," capability where stacks can write a Python script named ",(0,n.kt)("em",{parentName:"p"},"stack-advisor.py")," in the ",(0,n.kt)("em",{parentName:"p"},"services/")," folder. Example: ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/services/stack_advisor.py"},"HDP-2.0.6"),"."),(0,n.kt)("p",null,"Stack-advisor scripts automatically extend the parent stack-version's stack-advisor scripts. This allows newer stack-versions to change behavior without effecting earlier behavior."),(0,n.kt)("p",null,"Stack advisors provide information on 4 important aspects:"),(0,n.kt)("ol",null,(0,n.kt)("li",{parentName:"ol"},"Recommend layout of services on cluster"),(0,n.kt)("li",{parentName:"ol"},"Recommend service configurations"),(0,n.kt)("li",{parentName:"ol"},"Validate layout of services on cluster"),(0,n.kt)("li",{parentName:"ol"},"Validate service configurations")),(0,n.kt)("p",null,"By providing the stack-advisor.py file, one can control dynamically each of the above."),(0,n.kt)("p",null,"The main interface for the stack-advisor scripts contains documentation on how each of the above are called, and what data is provided"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-python"},'class StackAdvisor(object):\n"""\n  Abstract class implemented by all stack advisors. Stack advisors advise on stack specific questions.\n\n  Currently stack advisors provide following abilities:\n  - Recommend where services should be installed in cluster\n  - Recommend configurations based on host hardware\n  - Validate user selection of where services are installed on cluster\n  - Validate user configuration values\n\n  Each of the above methods is passed in parameters about services and hosts involved as described below.\n\n    @type services: dictionary\n    @param services: Dictionary containing all information about services selected by the user.\n\n      Example: {\n      "services": [\n        {\n          "StackServices": {\n            "service_name" : "HDFS",\n            "service_version" : "2.6.0.2.2",\n          },\n          "components" : [\n            {\n              "StackServiceComponents" : {\n                "cardinality" : "1+",\n                "component_category" : "SLAVE",\n                "component_name" : "DATANODE",\n                "display_name" : "DataNode",\n                "service_name" : "HDFS",\n                "hostnames" : []\n              },\n              "dependencies" : []\n            }, {\n              "StackServiceComponents" : {\n                "cardinality" : "1-2",\n                "component_category" : "MASTER",\n                "component_name" : "NAMENODE",\n                "display_name" : "NameNode",\n                "service_name" : "HDFS",\n                "hostnames" : []\n              },\n              "dependencies" : []\n            },\n            ...\n\n          ]\n        },\n        ...\n\n      ]\n    }\n  @type hosts: dictionary\n  @param hosts: Dictionary containing all information about hosts in this cluster\n    Example: {\n      "items": [\n        {\n          Hosts: {\n            "host_name": "c6401.ambari.apache.org",\n            "public_host_name" : "c6401.ambari.apache.org",\n            "ip": "192.168.1.101",\n            "cpu_count" : 1,\n            "disk_info" : [\n              {\n              "available" : "4564632",\n              "used" : "5230344",\n              "percent" : "54%",\n              "size" : "10319160",\n              "type" : "ext4",\n              "mountpoint" : "/"\n              },\n              {\n              "available" : "1832436",\n              "used" : "0",\n              "percent" : "0%",\n              "size" : "1832436",\n              "type" : "tmpfs",\n              "mountpoint" : "/dev/shm"\n              }\n            ],\n            "host_state" : "HEALTHY",\n            "os_arch" : "x86_64",\n            "os_type" : "centos6",\n            "total_mem" : 3664872\n          }\n        },\n        ...\n\n      ]\n    }\n\n    Each of the methods can either return recommendations or validations.\n\n    Recommendations are made in a Ambari Blueprints friendly format.\n\n    Validations are an array of validation objects.\n\n"""\n\n  def recommendComponentLayout(self, services, hosts):\n"""\n    Returns recommendation of which hosts various service components should be installed on.\n\n    This function takes as input all details about services being installed, and hosts\n    they are being installed into, to generate hostname assignments to various components\n    of each service.\n\n    @type services: dictionary\n    @param services: Dictionary containing all information about services selected by the user.\n\n    @type hosts: dictionary\n    @param hosts: Dictionary containing all information about hosts in this cluster\n    @rtype: dictionary\n    @return: Layout recommendation of service components on cluster hosts in Ambari Blueprints friendly format.\n\n        Example: {\n          "resources" : [\n            {\n              "hosts" : [\n                "c6402.ambari.apache.org",\n                "c6401.ambari.apache.org"\n              ],\n              "services" : [\n                "HDFS"\n              ],\n              "recommendations" : {\n                "blueprint" : {\n                  "host_groups" : [\n                    {\n                      "name" : "host-group-2",\n                      "components" : [\n                        { "name" : "JOURNALNODE" },\n                        { "name" : "ZKFC" },\n                        { "name" : "DATANODE" },\n                        { "name" : "SECONDARY_NAMENODE" }\n                      ]\n                    },\n                    {\n                      "name" : "host-group-1",\n                      "components" :\n                        { "name" : "HDFS_CLIENT" },\n                        { "name" : "NAMENODE" },\n                        { "name" : "JOURNALNODE" },\n                        { "name" : "ZKFC" },\n                        { "name" : "DATANODE" }\n                      ]\n                    }\n                  ]\n                },\n                "blueprint_cluster_binding" : {\n                  "host_groups" : [\n                    {\n                      "name" : "host-group-1",\n                      "hosts" : [ { "fqdn" : "c6401.ambari.apache.org" } ]\n                    },\n                    {\n                      "name" : "host-group-2",\n                      "hosts" : [ { "fqdn" : "c6402.ambari.apache.org" } ]\n                    }\n                  ]\n                }\n              }\n            }\n          ]\n        }\n"""\n    pass\n\n  def validateComponentLayout(self, services, hosts):\n"""\n    Returns array of Validation issues with service component layout on hosts\n\n    This function takes as input all details about services being installed along with\n    hosts the components are being installed on (hostnames property is populated for\n    each component).\n\n    @type services: dictionary\n    @param services: Dictionary containing information about services and host layout selected by the user.\n\n    @type hosts: dictionary\n    @param hosts: Dictionary containing all information about hosts in this cluster\n    @rtype: dictionary\n    @return: Dictionary containing array of validation items\n        Example: {\n          "items": [\n            {\n              "type" : "host-group",\n              "level" : "ERROR",\n              "message" : "NameNode and Secondary NameNode should not be hosted on the same machine",\n              "component-name" : "NAMENODE",\n              "host" : "c6401.ambari.apache.org"\n            },\n            ...\n\n          ]\n        }\n"""\n    pass\n\n  def recommendConfigurations(self, services, hosts):\n"""\n    Returns recommendation of service configurations based on host-specific layout of components.\n\n    This function takes as input all details about services being installed, and hosts\n    they are being installed into, to recommend host-specific configurations.\n\n    @type services: dictionary\n    @param services: Dictionary containing all information about services and component layout selected by the user.\n\n    @type hosts: dictionary\n    @param hosts: Dictionary containing all information about hosts in this cluster\n    @rtype: dictionary\n    @return: Layout recommendation of service components on cluster hosts in Ambari Blueprints friendly format.\n\n        Example: {\n         "services": [\n          "HIVE",\n          "TEZ",\n          "YARN"\n         ],\n         "recommendations": {\n          "blueprint": {\n           "host_groups": [],\n           "configurations": {\n            "yarn-site": {\n             "properties": {\n              "yarn.scheduler.minimum-allocation-mb": "682",\n              "yarn.scheduler.maximum-allocation-mb": "2048",\n              "yarn.nodemanager.resource.memory-mb": "2048"\n             }\n            },\n            "tez-site": {\n             "properties": {\n              "tez.am.java.opts": "-server -Xmx546m -Djava.net.preferIPv4Stack=true -XX:+UseNUMA -XX:+UseParallelGC",\n              "tez.am.resource.memory.mb": "682"\n             }\n            },\n            "hive-site": {\n             "properties": {\n              "hive.tez.container.size": "682",\n              "hive.tez.java.opts": "-server -Xmx546m -Djava.net.preferIPv4Stack=true -XX:NewRatio=8 -XX:+UseNUMA -XX:+UseParallelGC",\n              "hive.auto.convert.join.noconditionaltask.size": "238026752"\n             }\n            }\n           }\n          },\n          "blueprint_cluster_binding": {\n           "host_groups": []\n          }\n         },\n         "hosts": [\n          "c6401.ambari.apache.org",\n          "c6402.ambari.apache.org",\n          "c6403.ambari.apache.org"\n         ]\n        }\n"""\n    pass\n\n  def validateConfigurations(self, services, hosts):\n""""\n    Returns array of Validation issues with configurations provided by user\n    This function takes as input all details about services being installed along with\n    configuration values entered by the user. These configurations can be validated against\n    service requirements, or host hardware to generate validation issues.\n\n    @type services: dictionary\n    @param services: Dictionary containing information about services and user configurations.\n\n    @type hosts: dictionary\n    @param hosts: Dictionary containing all information about hosts in this cluster\n    @rtype: dictionary\n    @return: Dictionary containing array of validation items\n        Example: {\n         "items": [\n          {\n           "config-type": "yarn-site",\n           "message": "Value is less than the recommended default of 682",\n           "type": "configuration",\n           "config-name": "yarn.scheduler.minimum-allocation-mb",\n           "level": "WARN"\n          }\n         ]\n       }\n"""\n    pass\n')),(0,n.kt)("h4",{id:"examples-3"},(0,n.kt)("strong",{parentName:"h4"},"Examples")),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/stack_advisor.py#L23"},"Stack Advisor interface")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/stack_advisor.py#L303"},"Default Stack Advisor implementation - for all stacks")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/services/stack_advisor.py#L28"},"HDP (2.0.6) Default Stack Advisor implementation")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/services/stack_advisor.py#L807"},"YARN container size calculated")),(0,n.kt)("li",{parentName:"ul"},"Recommended configurations -",(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/stacks/HDP/2.0.6/services/stack_advisor.py#L222"},"HDFS"),",",(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/stacks/HDP/2.0.6/services/stack_advisor.py#L133"},"YARN"),",",(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/stacks/HDP/2.0.6/services/stack_advisor.py#L148"},"MapReduce2"),",",(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/stacks/HDP/2.0.6/services/stack_advisor.py#L245"},"HBase")," (HDP-2.0.6),",(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/stacks/HDP/2.0.6/services/stack_advisor.py#L148"},"HBase")," (HDP-2.3)"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/stacks/HDP/2.3/services/stack_advisor.py#L272"},"Delete HBase Bucket Cache configs on smaller machines")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/stacks/HDP/2.3/services/stack_advisor.py#L184"},"Specify maximum value for Tez config"))),(0,n.kt)("h3",{id:"properties"},"Properties"),(0,n.kt)("p",null,"Similar to stack configurations, most properties are defined at the service level, however there are global properties which can be defined at the stack-version level affecting across all services."),(0,n.kt)("p",null,"Some examples are: ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/properties/stack_tools.json#L2"},"stack-selector and conf-selector")," specific names or what ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/properties/stack_features.json#L5"},"stack versions certain stack features")," are supported by. Most of these properties were introduced in Ambari 2.4 version in the effort of parameterize stack information and facilitate the reuse of common-services code by other distributions."),(0,n.kt)("p",null,"Such properties can be defined in .json format in the ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/tree/trunk/ambari-server/src/main/resources/stacks/HDP/2.0.6/properties"},"properties folder")," of the stack."),(0,n.kt)("p",null,"More details about stack properties can be found on ",(0,n.kt)("a",{parentName:"p",href:"https://cwiki.apache.org/confluence/x/pgPiAw"},"Stack Properties section"),"."),(0,n.kt)("h3",{id:"widgets-1"},"Widgets"),(0,n.kt)("p",null,"At the stack-version level one can contribute heatmap entries to the main dashboard of the cluster."),(0,n.kt)("p",null,"Generally these heatmaps would be ones which apply to all services - like host level heatmaps."),(0,n.kt)("p",null,"Example: ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/stacks/HDP/2.0.6/widgets.json"},"HDP-2.0.6 contributes host level heatmaps")),(0,n.kt)("h3",{id:"kerberos-1"},"Kerberos"),(0,n.kt)("p",null,"We have seen previously the Kerberos descriptor at the service level."),(0,n.kt)("p",null,"One can be defined at the stack-version level also to describe identities across all services."),(0,n.kt)("p",null,"Read more about the Kerberos support and the Kerberos Descriptor in the ",(0,n.kt)("em",{parentName:"p"}," ",(0,n.kt)("a",{parentName:"em",href:"https://cwiki.apache.org/confluence/display/AMBARI/Automated+Kerberizaton"},"Automated Kerberization"))," page."),(0,n.kt)("p",null,"Example: ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/stacks/HDP/2.0.6/kerberos.json"},"Smoke tests user and SPNEGO user defined in HDP-2.0.6")),(0,n.kt)("h3",{id:"stack-upgrades"},"Stack Upgrades"),(0,n.kt)("p",null,"Ambari provides the ability to upgrade your cluster from a lower stack-version to a higher stack-version."),(0,n.kt)("p",null,"Each stack-version can define ",(0,n.kt)("em",{parentName:"p"},"upgrade-packs"),", which are XML files describing the upgrade process. These ",(0,n.kt)("em",{parentName:"p"},"upgrade-pack")," XML files are placed in the stack-version's ",(0,n.kt)("em",{parentName:"p"},"upgrades/")," folder."),(0,n.kt)("p",null,"Example: ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/tree/branch-2.2.1/ambari-server/src/main/resources/stacks/HDP/2.3/upgrades"},"HDP-2.3"),", ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/tree/branch-2.2.1/ambari-server/src/main/resources/stacks/HDP/2.4/upgrades"},"HDP-2.4")),(0,n.kt)("p",null,"Each stack-version should have an upgrade-pack for the next stack-version a cluster can ",(0,n.kt)("strong",{parentName:"p"},"upgrade to"),"."),(0,n.kt)("p",null,"Ex: ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/stacks/HDP/2.3/upgrades/upgrade-2.4.xml"},"Upgrade-pack from HDP-2.3 to HDP-2.4")),(0,n.kt)("p",null,"There are two types of upgrades:"),(0,n.kt)("table",null,(0,n.kt)("thead",{parentName:"table"},(0,n.kt)("tr",{parentName:"thead"},(0,n.kt)("th",{parentName:"tr",align:null},"Upgrade Type"),(0,n.kt)("th",{parentName:"tr",align:null},"Pros"),(0,n.kt)("th",{parentName:"tr",align:null},"Cons"))),(0,n.kt)("tbody",{parentName:"table"},(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Express Upgrade (EU)"),(0,n.kt)("td",{parentName:"tr",align:null},"Cluster unavailable - services are stopped during upgrade process"),(0,n.kt)("td",{parentName:"tr",align:null},"Much faster - clusters can be upgraded in a couple of hours")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Rolling Upgrade (RU)"),(0,n.kt)("td",{parentName:"tr",align:null},"Minimal cluster downtime - services available throughout upgrade process"),(0,n.kt)("td",{parentName:"tr",align:null},"Takes time (sometimes days depending on cluster size) due to incremental upgrade approach")))),(0,n.kt)("p",null,"Each component which has to be upgraded by Ambari should specify the ",(0,n.kt)("strong",{parentName:"p"},"versionAdvertised")," flag in the metainfo.xml."),(0,n.kt)("p",null,"This will tell Ambari to use the component's version and perform upgrade. Not specifying this flag will result in Ambari not upgrading the component."),(0,n.kt)("p",null,"Example: ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/common-services/HDFS/2.1.0.2.0/metainfo.xml#L33"},"HDFS NameNode")," (versionAdvertised=true), ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/common-services/AMBARI_METRICS/0.1.0/metainfo.xml#L33"},"AMS Metrics Collector")," (versionAdvertised=false)."),(0,n.kt)("h4",{id:"rolling-upgrades"},"Rolling Upgrades"),(0,n.kt)("p",null,"In Rolling Upgrade each service is upgraded with minimal downtime in mind. The general approach is to quickly upgrade the master components, followed by upgrading of workers in batches."),(0,n.kt)("p",null,"The service will not be available when masters are restarting. However when master components are in High Availability (HA), the service continues to be available through restart of each master."),(0,n.kt)("p",null,"You can read more about the Rolling Upgrade process via this ",(0,n.kt)("a",{parentName:"p",href:"http://hortonworks.com/blog/introducing-automated-rolling-upgrades-with-apache-ambari-2-0/"},"blog post")," and ",(0,n.kt)("a",{parentName:"p",href:"https://docs.hortonworks.com/HDPDocuments/Ambari-2.2.1.0/bk_upgrading_Ambari/content/_upgrading_HDP_perform_rolling_upgrade.html"},"documentation"),"."),(0,n.kt)("p",null,"Examples"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/stacks/HDP/2.2/upgrades/upgrade-2.2.xml"},"HDP-2.2.x to HDP-2.2.y")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/stacks/HDP/2.2/upgrades/upgrade-2.3.xml"},"HDP-2.2 to HDP-2.3")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/stacks/HDP/2.2/upgrades/upgrade-2.4.xml"},"HDP-2.2 to HDP-2.4")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/stacks/HDP/2.3/upgrades/upgrade-2.4.xml"},"HDP-2.3 to HDP-2.4"))),(0,n.kt)("h4",{id:"express-upgrades"},"Express Upgrades"),(0,n.kt)("p",null,"In Express Upgrade the goal is to upgrade entire cluster as fast as possible - even if it means cluster downtime. It is generally much faster than Rolling Upgrade."),(0,n.kt)("p",null,"For each service the components are first stopped, upgraded and then started."),(0,n.kt)("p",null,"You can read about Express Upgrade steps in this ",(0,n.kt)("a",{parentName:"p",href:"https://docs.hortonworks.com/HDPDocuments/Ambari-2.2.1.0/bk_upgrading_Ambari/content/_upgrading_HDP_perform_express_upgrade.html"},"documentation"),"."),(0,n.kt)("p",null,"Examples"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/stacks/HDP/2.1/upgrades/nonrolling-upgrade-2.3.xml"},"HDP-2.1 to HDP-2.3")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("a",{parentName:"li",href:"https://github.com/apache/ambari/blob/branch-2.2.1/ambari-server/src/main/resources/stacks/HDP/2.2/upgrades/nonrolling-upgrade-2.4.xml"},"HDP-2.2 to HDP-2.4"))),(0,n.kt)("h2",{id:"configuration-support-in-ambari"},"Configuration support in Ambari"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://cwiki.apache.org/confluence/display/AMBARI/Configuration+support+in+Ambari"},"Configuration support in Ambari")))}m.isMDXComponent=!0},9230:(e,a,t)=>{t.d(a,{Z:()=>r});const r=t.p+"assets/images/define-service-9bba55f25452b04797b9fd5fee978b9e.png"},9926:(e,a,t)=>{t.d(a,{Z:()=>r});const r=t.p+"assets/images/define-stack-f2edf8d59e0df1bbc1aece50a17e71a1.png"},1068:(e,a,t)=>{t.d(a,{Z:()=>r});const r=t.p+"assets/images/hooks-f2edf8d59e0df1bbc1aece50a17e71a1.png"},4331:(e,a,t)=>{t.d(a,{Z:()=>r});const r=t.p+"assets/images/scripts-folder-84e22cef867bda407686971117d6519e.png"},6145:(e,a,t)=>{t.d(a,{Z:()=>r});const r=t.p+"assets/images/scripts-a70dece11f1179d56a45ff9ac3c645c0.png"}}]);